---
title: "R Notebook"
output: html_notebook
---

This notebook showing the development of a model to predict antimicrobial peptides (AMPs) from amino acid sequences

```{r}
# Install the necessary packages
install.packages("Peptides", dependencies=TRUE)
install.packages("protr")
install.packages("seqinr")
install.packages("dplyr")
install.packages("stringr")
install.packages("corrplot")
install.packages("randomForest")
install.packages("pROC")
install.packages("tidyr")
install.packages("ggplot2")
install.packages("caret")
```

```{r}
# Load the necessary packages
library(Peptides)
library(protr)
library(seqinr)
library(dplyr)
library(stringr)
library(corrplot)
library(randomForest)
library(pROC)
library(tidyr)
library(ggplot2)
library(caret)
```

[**Data Importing**]{.underline}

Importing and cleaning of the training dataset found in "data/" of this repository.

The AMP dataset "amps.fasta" was sourced from DRAMP, an open access web database of known AMPs. The dataset consists of 3306 AMPs from bacteria.

The negative datset was obtained from UniProt using the following search criteria:

"(length:[5 TO 255]) NOT (keyword:KW-0930) NOT (keyword:KW-0929) NOT (keyword:KW-0472) NOT (keyword:KW-0964) NOT (keyword:KW-0051) NOT (keyword:KW-0800) NOT (keyword:AMP) NOT (keyword:anticancer) NOT (keyword:antifungal) NOT (keyword:KW-0044) NOT (keyword:defensive) NOT (keyword:toxic) AND (reviewed:true)"

This resulted in 11129 peptide sequences, that are "likely" not to be AMPs which will be used for the negative dataset, trimmed to the same number of sequences as AMP dataset for balance.

```{r}
# Input AMP Data from a fasta file
AMP_seqs <- read.fasta(file = "../Data/amps.fasta", seqtype = "AA")

# Input non-AMP DATA from a fasta file
non_AMP_seqs <- read.fasta(file = "../Data/non_amps.fasta", seqtype = "AA")

# Store sequences as a list
AMP_seq_chars <- sapply(AMP_seqs, function(x) paste(x, collapse = ""))
non_AMP_seq_chars <- sapply(non_AMP_seqs, function(x) paste(x, collapse = ""))

# Remove duplicate sequences
cat("Number of AMP sequences removed:", length(AMP_seq_chars) - length(unique(AMP_seq_chars)), "\n")
AMP_seq_chars <- unique(AMP_seq_chars)

cat("Number of Non-AMP sequences removed:", length(non_AMP_seq_chars) - length(unique(non_AMP_seq_chars)), "\n")
non_AMP_seq_chars <- unique(non_AMP_seq_chars)
```

```{r}
# Create Dataframes for AMP and non-AMP

# AMP dataframe
AMP_df<- data.frame(
  AMP_status = 1,
  class = c('AMP'),
  sequence = AMP_seq_chars,
  stringsAsFactors = FALSE
)

# nonAMP dataframe
non_AMP_df<- data.frame(
  AMP_status = 0,
  class = c('nonAMP'),
  sequence = non_AMP_seq_chars,
  stringsAsFactors = FALSE
)


```

```{r}
# Remove any non-standard amino acids
AMP_df <- AMP_df[!grepl("[^ACDEFGHIKLMNPQRSTVWY]", AMP_df$sequence), ]
non_AMP_df <- non_AMP_df[!grepl("[^ACDEFGHIKLMNPQRSTVWY]", non_AMP_df$sequence), ]


# Merge the two data frames, ensuring the number of nonAMPs is equal to AMP (balanced)
feature_df = rbind(AMP_df, sample_n(non_AMP_df, size=nrow(AMP_df))) 
```

[**Feature Creation**]{.underline}

```{r}
# Create some features using the Peptides package
feature_df <- feature_df %>%
  mutate(
    length = lengthpep(sequence),
    mw = mw(sequence),
    pI = pI(sequence),
    hydrophobicity = hydrophobicity(sequence),
    charge = charge(sequence),
    amphipathicity = hmoment(sequence),
    aliphatic_index = aIndex(sequence),
    boman_index = boman(sequence),
    hmoment = hmoment(sequence)
  )

# Creature a column for IDs
feature_df <- feature_df %>%
  mutate(id = sprintf("%05d", row_number())) %>%
  relocate(id, .before = 1)
```

```{r}
# Structural features added to the dataframe

# Tiny (A, C, G, S, T)
feature_df$tiny_prop <- str_count(feature_df$sequence, "[ACGST]") / str_length(feature_df$sequence)

# Small (A, B, C, D, G, N, P, S, T, V)
feature_df$small_prop <- str_count(feature_df$sequence, "[ABCDGNPSTV]")/ str_length(feature_df$sequence)

# Aliphatic (A, I, L, V)
feature_df$aliphatic_prop <- str_count(feature_df$sequence, "[AILV]")/ str_length(feature_df$sequence)

# Aromatic (F, H, W, Y)
feature_df$aromatic_prop <- str_count(feature_df$sequence, "[FHWY]")/ str_length(feature_df$sequence)

# Positive (H, K, R)
feature_df$pos_prop <- str_count(feature_df$sequence, "[HKR]")/ str_length(feature_df$sequence)

# Negative (D, E)
feature_df$neg_prop <- str_count(feature_df$sequence, "[DE]")/ str_length(feature_df$sequence)

# Charged (D, E, H, K, R)
feature_df$charged_prop <- str_count(feature_df$sequence, "[DEHKR]")/ str_length(feature_df$sequence)

# Polar (D, E, H, K, N, Q, R, S, T, Z)
feature_df$polar_prop <- str_count(feature_df$sequence, "[DEHKNQRSTZ]")/ str_length(feature_df$sequence)


```

[**Basic Plots**]{.underline}

Some feature plots were generated classified by AMP stauts: AMP or nonAMP to look for any identifiable features.

```{r}
# Create a list of the feature headings
key_features <- c("length", "mw", "pI", "hydrophobicity", "charge", "amphipathicity", "aliphatic_index", "boman_index", "hmoment")


key_plots <- feature_df %>%
  select(class, all_of(key_features)) %>%
  pivot_longer(
    cols = -class,
    names_to = "feature",
    values_to = "value"
  )

ggplot(key_plots, aes(x = value, fill = class)) +
  geom_histogram(
    bins = 30,
    alpha = 0.6,
    position = "identity"
  ) +
  facet_wrap(~ feature, scales = "free") +
  theme_bw() +
  labs(
    title = "Feature distributions for AMP vs nonAMP",
    x = "Feature value",
    y = "Count"
  )

```

```{r}
# Part 2 of features plotting: structural features

proportion_features <- c("tiny_prop", "small_prop", "aliphatic_prop", "aromatic_prop", "pos_prop", "neg_prop", "charged_prop", "polar_prop")

proportion_plots <- feature_df %>%
  select(class, all_of(proportion_features)) %>%
  pivot_longer(
    cols = -class,
    names_to = "feature",
    values_to = "value"
  )

ggplot(proportion_plots, aes(x = value, fill = class)) +
  geom_histogram(
    bins = 30,
    alpha = 0.6,
    position = "identity"
  ) +
  facet_wrap(~ feature, scales = "free") +
  theme_bw() +
  labs(
    title = "Feature distributions for AMP vs nonAMP",
    x = "Feature value",
    y = "Count"
  )
```

[**Correlation Analysis to Identify Redundant Features**]{.underline}

```{r}

# Create a dataframe of using only the numeric features
feature_mat <- feature_df %>%
  select(where(is.numeric))

# Compute the Pearson correlation matrix
cor_mat <- cor(feature_mat, method = "pearson")

# Visualise the correlation matrix
corrplot(
  cor_mat,
  method = "color",
  type = "upper",
  tl.cex = 0.7
)

# Identify highly correlated feature pairs
# abs(correlation) > 0.9 indicates strong correlation
# abs(correlation) < 1 removes self-correlations
high_cor <- which(abs(cor_mat) > 0.9 & abs(cor_mat) < 1, arr.ind = TRUE)

# Convert highly correlated pairs into a readable data frame
high_cor_pairs <- unique(
  data.frame(
    feature1 = rownames(cor_mat)[high_cor[, 1]],
    feature2 = colnames(cor_mat)[high_cor[, 2]],
    r = cor_mat[high_cor]
  )
)

high_cor_pairs
```

Correlation analysis revealed several highly redundant features, including molecular weight and peptide length (r = 0.99), amphipathicity and hydrophobic moment (r = 1.00), and aliphatic content measures (r \> 0.93). To reduce redundancy and improve interpretability, one feature from each highly correlated pair was removed prior to downstream analyses.

```{r}
# Remove reduntant pairs
feature_df <- feature_df %>%
  select(
    -mw,
    -hmoment,
    -aliphatic_prop,
    -boman_index   
  )
```

[**PCA Analysis**]{.underline}

```{r}
# Recreate the numeric dataframe post-reduction of redundant pairs
feature_mat_red <- feature_df %>%
  select(where(is.numeric))

# Perform PCA
pca_red <- prcomp(feature_mat_red, scale. = TRUE)


# Create a dataframe of the first two principal components 
pca_df_red <- data.frame(
  PC1 = pca_red$x[, 1],
  PC2 = pca_red$x[, 2],
  class = feature_df$class
)

# Visualise the results
ggplot(pca_df_red, aes(PC1, PC2, color = class)) +
  geom_point(alpha = 0.6) +
  theme_bw() +
  labs(title = "PCA")

```

Principal Component Analysis (PCA) was applied to the reduced feature set to visualise the structure of the data. The first two principal components show substantial overlap between AMP and non-AMP, indicating that the classes are not linearly separable. This is consistent with the complex and overlapping physicochemical properties of peptide sequences. The observed overlap supports the use of a non-linear classifier, such as Random Forest, which can exploit higher-dimensional feature interactions beyond linear boundaries.

[**Initial Model Building**]{.underline}

```{r}
# Splitting the data
set.seed(123)

#use 70% of dataset as training set and 30% as test set 
train <- feature_df %>% dplyr::sample_frac(0.70)
test  <- dplyr::anti_join(feature_df, train, by = 'id')
```

Model 1: Logistic Regression

```{r}
# Logistic regression using just 5-10 most promising features

# Most promising features
selected_features <- c(
  "length",
  "charge",
  "hydrophobicity",
  "amphipathicity",
  "aliphatic_index",
  "pI"
)

# Subset training and test data to selected features
# AMP_status is the binary response variable
train_lr <- train[, c("AMP_status", selected_features)]
test_lr  <- test[,  c("AMP_status", selected_features)]

# Fit a logistic regression model
lr_model <- glm(
  AMP_status ~ .,
  data = train_lr,
  family = binomial
)

summary(lr_model)
```

A logistic regression model was fitted using a reduced set of biologically relevant features. All selected predictors showed statistically significant associations with antimicrobial activity (p \< 0.001). Positive coefficients for hydrophobicity, amphipathicity, and isoelectric point indicate that peptides with these properties are more likely to be antimicrobial, consistent with known AMP mechanisms

[Evaluation of Logistic Regression Model]{.underline}

```{r}
# Predict probabilities on the test set
prob_amp <- predict(lr_model, newdata = test_lr, type = "response")

# Class predictions (0 = nonAMP, 1 = AMP)
pred_class <- ifelse(prob_amp >= 0.5, 1, 0)

# Confusion matrix
cm <- table(
  Predicted = pred_class,
  Actual = test_lr$AMP_status
)

cm

# Accuracy
accuracy <- sum(diag(cm)) / sum(cm)

# Sensitivity (Recall / TPR)
sensitivity <- cm["1", "1"] / sum(cm[, "1"])

# Specificity (TNR)
specificity <- cm["0", "0"] / sum(cm[, "0"])

# MCC
TP <- as.numeric(cm["1", "1"])
TN <- as.numeric(cm["0", "0"])
FP <- as.numeric(cm["1", "0"])
FN <- as.numeric(cm["0", "1"])

mcc <- (TP * TN - FP * FN) /
       sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))

# ROC and AUC
roc_obj <- roc(
  response = test_lr$AMP_status,
  predictor = prob_amp,
  levels = c(0, 1),
  direction = "<"
)

auc_val <- auc(roc_obj)

plot(roc_obj, main = "Logistic Regression ROC")

# Final summary metrics
lr_metrics <- data.frame(
  Accuracy = accuracy,
  Sensitivity = sensitivity,
  Specificity = specificity,
  AUC = as.numeric(auc_val),
  MCC = mcc
)

lr_metrics


```

Logistic regression achieved an accuracy of \~70% with an AUC of \~0.75, indicating moderate discriminative performance. While sensitivity was relatively high (0.77), specificity was lower (0.64), reflecting a tendency to misclassify non-antimicrobial peptides. The Matthews Correlation Coefficient (0.41) further indicates limited predictive power. These results highlight the limitations of linear models for AMP classification and justify the use of a Random Forest classifier, which achieved substantially higher performance.

[**Model 2: Random Forest**]{.underline}

```{r}
train$class <- factor(train$class, levels = c("nonAMP", "AMP"))
test$class  <- factor(test$class,  levels = c("nonAMP", "AMP"))

# Train a Random Forest classifier
rf <- randomForest(
  class ~ .,
  data = train,
  ntree = 500,
  importance = TRUE
)

# Predict class labels on the test set
pred_class <- predict(rf, newdata = test)

# Predict class probabilities on the test set
pred_prob <- predict(rf, newdata = test, type = "prob")[, "AMP"]

# Generate confusion matrix
rf_cm <- table(Predicted = pred_class, Actual = test$class)
rf_cm


```

[Evaluation of Random Forest]{.underline}

```{r}

# Extract counts
rf_TP <- as.numeric(rf_cm["AMP", "AMP"])
rf_TN <- as.numeric(rf_cm["nonAMP", "nonAMP"])
rf_FP <- as.numeric(rf_cm["AMP", "nonAMP"])
rf_FN <- as.numeric(rf_cm["nonAMP", "AMP"])

# Metrics
rf_accuracy <- (rf_TP + rf_TN) / sum(rf_cm)
rf_sensitivity <- rf_TP / (rf_TP + rf_FN)
rf_specificity <- rf_TN / (rf_TN + rf_FP)

rf_mcc <- (rf_TP * rf_TN - rf_FP * rf_FN) /
       sqrt((rf_TP + rf_FP) * (rf_TP + rf_FN) * (rf_TN + rf_FP) * (rf_TN + rf_FN))

# AUC
rf_roc_obj <- roc(test$class, pred_prob, levels = c("nonAMP", "AMP"))
rf_auc_val <- as.numeric(auc(rf_roc_obj))

# Final summary
rf_metrics <- data.frame(
  Accuracy = rf_accuracy,
  Sensitivity = rf_sensitivity,
  Specificity = rf_specificity,
  AUC = rf_auc_val,
  MCC = rf_mcc
)

rf_metrics
```

Comparison Between Models

```{r}
combined <- bind_rows(
  "Linear Regression" = lr_metrics,
  "Random Forest" = rf_metrics,
  .id = "Model"
)

combined
```

[Random Forest Model Refinement]{.underline}

```{r}

# Ways to improve the RF model
## Add additional features (Individual aa composition, di-amino acid composition (400 features!))
## Tweak model parameters
## Have a more imbalanced dataset? i.e. favouring nonAMP

aa <- c("A","C","D","E","F","G","H","I","K","L",
        "M","N","P","Q","R","S","T","V","W","Y")

# Add individual amino acid proportion to the feature dataframe
for (a in aa) {
  feature_df[[paste0(a, "_prop")]] <-
    str_count(feature_df$sequence, fixed(a)) /
    str_length(feature_df$sequence)
}

# Splitting the data
set.seed(22)

splitting <- createDataPartition(feature_df$class, p = 0.7, list = FALSE)

train_2 <- feature_df[splitting, ]
test_2  <- feature_df[-splitting, ]

# Create test and train DF without leakage features
train_rf <- train_2 %>% select(-sequence, -id, -AMP_status)
test_rf  <- test_2  %>% select(-sequence, -id, -AMP_status)


train_rf$class <- factor(train_rf$class, levels = c("nonAMP", "AMP"))
test_rf$class  <- factor(test_rf$class,  levels = c("nonAMP", "AMP"))

x_train <- train_rf %>% select(-class)
y_train <- train_rf$class

tuned <- tuneRF(
  x = x_train,
  y = y_train,
  ntreeTry = 500,
  stepFactor = 1.5,
  improve = 0.01,
  trace = TRUE
)
```

[**Final Evaluation**]{.underline}

```{r}
set.seed(22)

best_mtry <- tuned[which.min(tuned[, "OOBError"]), "mtry"]

# Train model using the best mtry
rf <- randomForest(
  class ~ .,
  data = train_rf,
  ntree = 1000,
  mtry = best_mtry,
  classwt = c(nonAMP = 1, AMP = 3),
  importance = TRUE
)
```

```{r}
# Predictions
pred_class <- predict(rf, newdata = test_rf)
pred_prob  <- predict(rf, newdata = test_rf, type = "prob")[, "AMP"]

# Confusion matrix
confusionMatrix(pred_class, test_rf$class)

# ROC
roc_obj <- roc(
  response = test_rf$class,
  predictor = pred_prob,
  levels = c("nonAMP", "AMP")
)
auc(roc_obj)
plot(roc_obj)

# Variable importance
varImpPlot(rf, n.var = 15)
```

Save Model - DO NOT RUN

```{r}
#saveRDS(rf, file = "../R/model/rf_model.rds")
```
